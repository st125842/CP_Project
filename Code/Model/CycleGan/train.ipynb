{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bf7cb4-2a4c-48df-8636-5c9358ae4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f73769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83663af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d516c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disciminator_model import Discriminator\n",
    "from generator_model import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaad94b8-04cc-4d5d-8e2c-e404f4ad6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(3,3).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2a2901-b579-4ac4-bc99-585b80f8b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_train,path_test,imgz=256): \n",
    "        self.data_train = glob(path_train + '/*' + '.jpg')\n",
    "        self.data_test = glob(path_test + '/*' + '.jpg')\n",
    "        self.imgz = imgz\n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.data_train)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #### train #####\n",
    "        img_train = cv2.imread(self.data_train[idx])\n",
    "        # print(self.data_train[idx])\n",
    "        h,w,c = img_train.shape\n",
    "        img_train_resize = cv2.resize(img_train,(self.imgz,self.imgz))\n",
    "        img_train_resize = img_train_resize /255\n",
    "        img_train_resize = np.transpose(img_train_resize, (2, 0, 1))  \n",
    "        img_train_resize = torch.tensor(img_train_resize, dtype=torch.float32)\n",
    "        #### test #####\n",
    "        \n",
    "        img_test = cv2.imread(self.data_test[idx])\n",
    "        # print(self.data_test[idx])\n",
    "        h,w,c = img_test.shape\n",
    "        img_test_resize = cv2.resize(img_test,(self.imgz,self.imgz))\n",
    "        img_test_resize = img_test_resize /255\n",
    "        img_test_resize = np.transpose(img_test_resize, (2, 0, 1))  \n",
    "        img_test_resize = torch.tensor(img_test_resize, dtype=torch.float32)\n",
    "        return img_train_resize,img_test_resize\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0893ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "\n",
    "def train_fn(disc_H,disc_Z,gen_Z,gen_H,loader,opt_disc,opt_gen,l1,mse,d_scaler,g_scaler):\n",
    "    loop = tqdm(loader,leave=True)\n",
    "    \n",
    "    for idx,(ct,mri) in enumerate(loop):\n",
    "        ct = ct.to('cuda')\n",
    "        mri = mri.to('cuda')\n",
    "        #### Decriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake_ct = gen_H(mri)\n",
    "            D_ct_real = disc_H(ct)\n",
    "            D_ct_fake = disc_H(fake_ct.detach())\n",
    "            D_ct_real_loss = mse(D_ct_real, torch.ones_like(D_ct_real))\n",
    "            D_ct_fake_loss = mse(D_ct_fake, torch.zeros_like(D_ct_fake))\n",
    "            D_ct_loss = D_ct_real_loss + D_ct_fake_loss\n",
    "            \n",
    "            fake_mri = gen_Z(ct)\n",
    "            D_mri_real = disc_Z(mri)\n",
    "            D_mri_fake = disc_Z(fake_mri.detach())\n",
    "            D_mri_real_loss = mse(D_mri_real, torch.ones_like(D_mri_real))\n",
    "            D_mri_fake_loss = mse(D_mri_fake, torch.zeros_like(D_mri_fake))\n",
    "            D_mri_loss = D_mri_real_loss + D_mri_fake_loss\n",
    "            \n",
    "            D_loss = (D_ct_loss + D_mri_loss)/2\n",
    "        \n",
    "        opt_disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "        \n",
    "        #### Generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_ct_fake = disc_H(fake_ct)\n",
    "            D_mri_fake = disc_Z(fake_mri)\n",
    "            loss_G_ct = mse(D_ct_fake,torch.ones_like(D_ct_fake))\n",
    "            loss_G_mri = mse(D_mri_fake,torch.ones_like(D_mri_fake))\n",
    "            \n",
    "            # cycle loss\n",
    "            cycle_mri = gen_Z(fake_ct)\n",
    "            cycle_ct = gen_H(fake_mri)\n",
    "            cycle_mri_loss = l1(mri,cycle_mri)\n",
    "            cycle_ct_loss = l1(ct,cycle_ct)\n",
    "            \n",
    "            # identity loss\n",
    "            identity_mri = gen_Z(mri)\n",
    "            identity_ct = gen_H(ct)\n",
    "            identity_mri_loss = l1(mri,identity_mri)\n",
    "            identity_ct_loss = l1(ct,identity_ct)\n",
    "            \n",
    "            # add all together\n",
    "            g_loss = (\n",
    "                loss_G_ct + loss_G_mri + cycle_ct_loss*10 + cycle_mri_loss*10 + identity_ct_loss*0 + identity_mri_loss*0\n",
    "            )\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(g_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "        \n",
    "        if idx % 100 ==0:\n",
    "            save_image(fake_ct,f\"img_result/ct_{idx}.png\")\n",
    "            save_image(fake_mri,f\"img_result/mri_{idx}.png\")\n",
    "    torch.save(gen_H.state_dict(), f\"genH.pth\")\n",
    "    torch.save(gen_Z.state_dict(), f\"genZ.pth\")\n",
    "    torch.save(disc_H.state_dict(), f\"discH.pth\")\n",
    "    torch.save(disc_Z.state_dict(), f\"discZ.pth\")\n",
    "\n",
    "    # print(f\"✅ Models saved for epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671f99fe-4af7-4832-89d3-e599e50e8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow( torch.permute(test.__getitem__(0),(1,2,0)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157afcb1-0042-4bb0-9d71-474280dddf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet('../../ct_mr_data/train/mr/','../../ct_mr_data/train/ct/')\n",
    "test_dataset = DataSet('../../ct_mr_data/val//mr/','../../ct_mr_data/val/ct/')\n",
    "\n",
    "# test_dataset = DataSet('../Dataset/images/trainB/','.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83379de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15495"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc0adc0-30e3-4316-b5a9-a95cdd198f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader( \n",
    "    dataset=train_dataset, \n",
    "    batch_size=8, \n",
    "    shuffle=True, \n",
    ") \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader( \n",
    "    dataset=test_dataset, \n",
    "    batch_size=1, \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4026c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_H = Discriminator(in_channels=3).to('cuda')\n",
    "disc_Z = Discriminator(in_channels=3).to('cuda')\n",
    "gen_Z = Generator(img_channels=3,num_residuals=4).to('cuda')\n",
    "geh_H = Generator(img_channels=3,num_residuals=4).to('cuda')\n",
    "opt_disc = torch.optim.Adam(list(disc_H.parameters()) + list(disc_Z.parameters()),\n",
    "                           lr=0.0002,\n",
    "                            betas=(0.5,0.999)\n",
    "                           )\n",
    "opt_gen = torch.optim.Adam(list(gen_Z.parameters()) + list(geh_H.parameters()),\n",
    "                           lr=0.0002,\n",
    "                            betas=(0.5,0.999)\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c0d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d545bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiw00\\AppData\\Local\\Temp\\ipykernel_4608\\1536344252.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  g_scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\kiw00\\AppData\\Local\\Temp\\ipykernel_4608\\1536344252.py:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  d_scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf77ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1937 [00:00<?, ?it/s]C:\\Users\\kiw00\\AppData\\Local\\Temp\\ipykernel_4608\\3990151355.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\kiw00\\AppData\\Local\\Temp\\ipykernel_4608\\3990151355.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|██████████| 1937/1937 [43:20<00:00,  1.34s/it]\n",
      "100%|██████████| 1937/1937 [47:55<00:00,  1.48s/it]\n",
      "100%|██████████| 1937/1937 [37:51<00:00,  1.17s/it] \n",
      "100%|██████████| 1937/1937 [32:25<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:21<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:21<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:21<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:20<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:21<00:00,  1.00s/it]\n",
      "100%|██████████| 1937/1937 [32:48<00:00,  1.02s/it]\n",
      " 29%|██▉       | 559/1937 [10:03<24:48,  1.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdisc_Z\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgen_Z\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgeh_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmse\u001b[49m\u001b[43m,\u001b[49m\u001b[43md_scaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mg_scaler\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mtrain_fn\u001b[39m\u001b[34m(disc_H, disc_Z, gen_Z, gen_H, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler)\u001b[39m\n\u001b[32m     53\u001b[39m opt_gen.zero_grad()\n\u001b[32m     54\u001b[39m g_scaler.scale(g_loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mg_scaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m g_scaler.update()\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx % \u001b[32m100\u001b[39m ==\u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiw00\\Documents\\work\\AIT\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:465\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    462\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    463\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiw00\\Documents\\work\\AIT\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:359\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    353\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m     **kwargs: Any,\n\u001b[32m    357\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    358\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf_per_device\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    360\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kiw00\\Documents\\work\\AIT\\.venv\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:359\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    352\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    353\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m     **kwargs: Any,\n\u001b[32m    357\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    358\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    360\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train_fn(disc_H,disc_Z,gen_Z,geh_H,train_loader,opt_disc,opt_gen,l1,mse,d_scaler,g_scaler)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ce196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e2bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6828baa-b2da-418b-b0fc-38eee4dd1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# model = Model(3,3).to('cuda')\n",
    "# loss_fn =L1_SSIM_Loss()\n",
    "# lr = 1e-2\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fdf6f-5e5b-4d2a-912b-7b74d8338541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# all_losses = []  # store mean loss for each epoch\n",
    "# best_val_loss = float(\"inf\")  # initialize with infinity\n",
    "# best_model_path = \"best_model.pth\"\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print('Epoch:', epoch)\n",
    "    \n",
    "#     # -------------------- TRAINING --------------------\n",
    "#     model.train()\n",
    "#     train_losses = []\n",
    "#     for b, (X, y) in enumerate(train_loader):\n",
    "#         X, y = X.to('cuda'), y.to('cuda')\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         yHat = model(X)\n",
    "#         loss = loss_fn(yHat, y)  # compute loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_losses.append(loss.item())\n",
    "    \n",
    "#     epoch_loss = sum(train_losses) / len(train_losses)\n",
    "#     all_losses.append(epoch_loss)\n",
    "#     print('Train Loss Mean:', epoch_loss)\n",
    "#     print(f'----------------------- End {epoch + 1} {b+1}/{len(train_loader)} ------------------')\n",
    "    \n",
    "#     # -------------------- EVALUATION --------------------\n",
    "#     model.eval()\n",
    "#     val_losses = []\n",
    "#     with torch.no_grad():  # no gradient computation during evaluation\n",
    "#         for X_val, y_val in test_loader:\n",
    "#             X_val, y_val = X_val.to('cuda'), y_val.to('cuda')\n",
    "#             yHat_val = model(X_val)\n",
    "#             val_loss = loss_fn(yHat_val, y_val)\n",
    "#             val_losses.append(val_loss.item())\n",
    "    \n",
    "#     if val_losses:\n",
    "#         val_epoch_loss = sum(val_losses) / len(val_losses)\n",
    "#         print('Validation Loss Mean:', val_epoch_loss)\n",
    "        \n",
    "#         # -------- Save best model --------\n",
    "#         if val_epoch_loss < best_val_loss:\n",
    "#             best_val_loss = val_epoch_loss\n",
    "#             torch.save(model.state_dict(), 'best_model/' + best_model_path)\n",
    "#             print(f\"✅ Best model saved (val_loss={val_epoch_loss:.6f})\")\n",
    "    \n",
    "# # -------------------- SAVE TRAINING LOSSES --------------------\n",
    "# all_losses = np.array(all_losses)\n",
    "# np.save('losses.npy', all_losses)\n",
    "# print(\"Training losses saved to losses.npy\")\n",
    "# print(f\"Best model path: {best_model_path}, Best val_loss={best_val_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a193d-ecc1-4e46-92e9-45cb013e42af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e64366-9a9b-48df-b644-b1eb79b671e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee288b4b-4581-4af0-aaf6-13881c54ea0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIT (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
